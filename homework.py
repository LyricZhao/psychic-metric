import random
import numpy as np


def binary_classification_metrics(pred, target):
    # The inputs will be generated by the following codes:
    # pred = np.array([random.random() for i in range(100)])
    # target = np.array([random.randint(0, 1) for i in range(100)])
    # =====================   Here to compute the metrics   ======================== #
    assert len(pred) == len(target) and len(target) > 0
    label = np.maximum(np.sign(pred - 0.5), 0)
    tn, fp, fn, tp = 0, 0, 0, 0
    for i in range(len(label)):
        tn += (label[i] == 0 and target[i] == 0)
        fp += (label[i] == 0 and target[i] == 1)
        fn += (label[i] == 1 and target[i] == 0)
        tp += (label[i] == 1 and target[i] == 1)
    accuracy_score = (tn + tp) / (tn + fp + fn + tp)
    precision_score = tp / (tp + fp)
    recall_score = tp / (tp + fn)
    f1_score = 2 * recall_score * precision_score / (recall_score + precision_score)
    roc_auc_score = 0  # TODO
    # ===================== END OF BLOCK ======================= #
    return accuracy_score, precision_score, recall_score, f1_score, roc_auc_score


def multiclass_classification_metrics(pred, target):
    # The inputs will be generated by the following codes:
    # n = 200
    # target = np.array([random.randint(0, 9) for i in range(n)])
    # pred = np.array([random.randint(0, 9) for i in range(n)])
    # =====================   Here to compute the metrics   ======================== #
    raise NotImplementedError
    # ===================== END OF BLOCK ======================= #
    return accuracy_score, macro_precision_score, macro_recall_score, macro_f1_score
    # Comment: What is the micro scores in this case?


def multilabel_classification_metrics(pred, target):
    # Binary classification for 4 different labels.
    # The inputs will be generated by the following codes:
    # n = 300
    # target = np.array([[random.randint(0,1) for j in range(4)] for i in range(n)])
    # pred = np.array([[random.random() for j in range(4)] for i in range(n)])
    # =====================   Here to compute the metrics   ======================== #
    # Hint: compute the confusion matrix first
    raise NotImplementedError
    # ===================== END OF BLOCK ======================= #
    return accuracy_score, macro_precision_score, macro_recall_score, macro_f1_score, \
           micro_precision_score, micro_recall_score, micro_f1_score


def ranking_metrics(pred, rel):
    # Suppose we have n items, each with a real value rel[i] and a predicted value pred[i]
    # NDCG is Normalized Discounted cumulative gain. intro: https://en.wikipedia.org/wiki/Discounted_cumulative_gain
    # The inputs will be generated by the following codes:
    # n = 30
    # rel = [random.random() for i in range(n)]
    # pred = [random.random() for i in range(n)]
    # =====================   Here to compute the metrics   ======================== #
    raise NotImplementedError
    # ===================== END OF BLOCK ======================= #
    return ndcg_score
